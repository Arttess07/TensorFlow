{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción: Personalizar funciones de pérdida con hiperparámetros\n",
    "\n",
    "En este pequeño ejercicio vamos a definir una clase que nos permita crear una función de pérdida con hiperparámetros personalizados. Esto nos va a permitir iterar sobre la función de pérdida cambiando el valor de los hiperparámetros definidos.\n",
    "\n",
    "1. Importar librerías\n",
    "2. Creación de arrays\n",
    "3. Definimos funciones de pérdida personalizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.losses import Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creación de arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "Ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Funciones de pérdida funcionalizadas\n",
    "\n",
    "En esta sección vamos a definir funciones y classes para la métrica de error Huber Loss.\n",
    "Primero vamos a crear una \"wrapped formula\" que defina el hiperparámetro deseado de una fórmula dentro de otra.\n",
    "En la segunda instancia vamos a deifinir uns clase de pérdida, que nos sirva para poder usar la función de pérdida directo en nuestro modelo como si estuviera integrada dentro de la librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss_threshold(threshold):\n",
    "    def huber_loss(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        small_error = tf.abs(error) <= threshold\n",
    "        small_error_loss = tf.square(error) / 2\n",
    "        big_error_loss = threshold * (tf.abs(error) - (0.5 * threshold))\n",
    "        return(tf.where(small_error, small_error_loss, big_error_loss))\n",
    "    return huber_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "[[18.723654]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss=huber_loss_threshold(threshold=1))\n",
    "model.fit(Xs, Ys, epochs=500, verbose=0)\n",
    "print(model.predict(np.array([10.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(Loss):\n",
    "    threshold = 1\n",
    "    def __init__(self, threshold):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        small_error = tf.abs(error) <= self.threshold\n",
    "        small_error_loss = tf.square(error) / 2\n",
    "        big_error_loss = self.threshold * (tf.abs(error) - (0.5 * self.threshold))\n",
    "        return tf.where(small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "[[5.256429]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss=HuberLoss(threshold=1))\n",
    "model.fit(Xs, Ys, epochs=500, verbose=0)\n",
    "print(model.predict(np.array([10.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusiones\n",
    "\n",
    "Personalizar funciones de pérdida nos ayuda a eficientar la manera en la que entrenamos los modelos.\n",
    "Esto nos permite iterar los modelos entrenandolos de manera que su resultado sea más efectivo cuando buscamos predecir con una regresión.\n",
    "\n",
    "Crear formulas wrapped o classes nos permiten iterar sobre hiperparámetros de nuestra función de pérdida.\n",
    "Esto nos ayuda a iterar sobre un modelo de manera más sencilla y de manera personalizada a las metas de entrenamiento y funcionamiento del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
