{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción: Crear funciones de pérdida personalizadas Huber\n",
    "\n",
    "En este pequeño ejercicio vamos a crear y poner en práctica la creación de una función de pérdida personalizada.\n",
    "Esto es muy útil ya que existen casos en que las funciones integradas dentro de las librerías no son la opción ideal.\n",
    "Esto nos ayuda a iterar sobre los parámetros y entrenar el modelo de manera más eficiente.\n",
    "Es similar a usar un función cómo objetos y modificar los parámetros dentro de la función para iterar sobre su funcionamiento dentro de un modelo.\n",
    "\n",
    "Pasos a seguir:\n",
    "\n",
    "1. Importar librerías para creación del modelo\n",
    "2. Crear un array con información a tratar\n",
    "3. Creacrión de modelo\n",
    "4. Definir función de pérdida e implementarla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Crear array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "Ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "[[18.975628]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "model.fit(Xs, Ys, epochs=500, verbose=0)\n",
    "print(model.predict(np.array([10.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Definir función de pérdida\n",
    "Vamos a utilizar la funciónj personalizada de Huber.\n",
    "Esta función permite verificar si el error es pequeño o grande.\n",
    "Funciona de tal manera que no se sesaga por los valores atípicos.\n",
    "Trabaja de manera cuadrática para valores que sean más pequeños a nuestro límite de error y de forma linear para valores más grandes.\n",
    "Asignamos el límite en base a el error absoluto o residuales.\n",
    "El error absoluto es la diferencia entre los resultados reales esperados, menos las predicciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(y_true, y_pred):\n",
    "    threshold = 1\n",
    "    error = y_true - y_pred\n",
    "    small_error = tf.abs(error) <= threshold\n",
    "    small_error_loss = tf.square(error) / 2\n",
    "    big_error_loss = threshold * (tf.abs(error) - (0.5 * threshold))\n",
    "    return tf.where(small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002C80021B740> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "[[18.700933]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss=huber_loss)\n",
    "model.fit(Xs, Ys, epochs=500, verbose=0)\n",
    "print(model.predict(np.array([10.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusiones\n",
    "\n",
    "Al utilizar TensorFlow podemos crear operaciones vectorizadas que no necesitan hacer un loop con if para funcionar.\n",
    "De esta manera podemos crear una fórmula de pérdida basada en los vectores ingresados.\n",
    "Esto es posible creando una condicíon usando el método .where\n",
    "\n",
    "Al personalizar nuestra propias funciones de pérdida podemos iterar sobre los modelos de tal forma que mejoramos el funcionamiento en base al entrenamiento esperado.\n",
    "Gracias a la bondad de TensrFlow podemos hacer esto posible y mejorar la caldiad de nuestros modelos de regresión."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
